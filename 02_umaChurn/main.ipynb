{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "# в описании вакансии в требованиях указаны библиотеки бустинга\n",
    "# добавим их ;)\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import  LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, X, y, CV=5, scoring='roc_auc'):\n",
    "    '''Сравнение моделей по метрике roc-auc на кросс-валидации''' \n",
    "\n",
    "    results = {}\n",
    "    for model in tqdm.tqdm(models):\n",
    "        name_model = str(model)[:str(model).find('(')]\n",
    "        print(name_model, end=' ')\n",
    "        curr_cv = cross_val_score(model, X, y, cv=CV, scoring='roc_auc')\n",
    "        print('{}-fold CV is : {} +/- {}'.format(CV, curr_cv.mean().round(4), curr_cv.std().round(4)))\n",
    "        results.update({name_model:[curr_cv.mean().round(4), curr_cv]})\n",
    "    max_results = {k:v for k, v in results.items() if v == max(results.values())}\n",
    "    print(f'Max results {max_results.keys()} = {max(results.values())}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_ADDITIONAL_DATA.csv',\n",
       " 'TEST_PREPARED.csv',\n",
       " 'TEST_RAW_DATA.csv',\n",
       " 'test_submit_example.csv',\n",
       " 'TRAIN_ADDITIONAL_DATA.csv',\n",
       " 'TRAIN_PREPARED.csv',\n",
       " 'TRAIN_RAW_DATA.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим список csv файлов\n",
    "PATH = 'Churn_task/'\n",
    "files = [filename for filename in os.listdir(PATH) if filename[-3:] == 'csv']\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем данные\n",
    "train = pd.read_csv(PATH + 'TRAIN_PREPARED.csv')\n",
    "train_raw = pd.read_csv(PATH + 'TRAIN_PREPARED.csv')\n",
    "train_add = pd.read_csv(PATH + 'TRAIN_ADDITIONAL_DATA.csv')\n",
    "test = pd.read_csv(PATH + 'TEST_PREPARED.csv') \n",
    "test_raw = pd.read_csv(PATH + 'TEST_RAW_DATA.csv')\n",
    "test_add = pd.read_csv(PATH + 'TEST_ADDITIONAL_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_date</th>\n",
       "      <th>days_to_end</th>\n",
       "      <th>email</th>\n",
       "      <th>first_date</th>\n",
       "      <th>last_date</th>\n",
       "      <th>num_country_max_1days</th>\n",
       "      <th>num_city_max_1days</th>\n",
       "      <th>android_max_1days</th>\n",
       "      <th>smarttv_max_1days</th>\n",
       "      <th>iphone_max_1days</th>\n",
       "      <th>...</th>\n",
       "      <th>apple_max_30days</th>\n",
       "      <th>pc_max_30days</th>\n",
       "      <th>activity_1to3</th>\n",
       "      <th>activity_1to7</th>\n",
       "      <th>activity_1to14</th>\n",
       "      <th>activity_7to14</th>\n",
       "      <th>activity_7to21</th>\n",
       "      <th>activity_7to30</th>\n",
       "      <th>activity_14to30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-02 00:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>8ba752f2c5</td>\n",
       "      <td>2019-02-10 00:00:00</td>\n",
       "      <td>2019-03-13 09:36:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-02 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>752a6d96f7</td>\n",
       "      <td>2018-10-28 00:00:00</td>\n",
       "      <td>2019-04-01 20:51:29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.521792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-02 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>827f6afef3</td>\n",
       "      <td>2018-12-14 00:00:00</td>\n",
       "      <td>2019-04-01 18:00:49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937031</td>\n",
       "      <td>0.832238</td>\n",
       "      <td>0.598121</td>\n",
       "      <td>0.638308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cut_date  days_to_end       email           first_date  \\\n",
       "0  2019-04-02 00:00:00           11  8ba752f2c5  2019-02-10 00:00:00   \n",
       "1  2019-04-02 00:00:00           10  752a6d96f7  2018-10-28 00:00:00   \n",
       "2  2019-04-02 00:00:00            4  827f6afef3  2018-12-14 00:00:00   \n",
       "\n",
       "             last_date  num_country_max_1days  num_city_max_1days  \\\n",
       "0  2019-03-13 09:36:59                    0.0                 0.0   \n",
       "1  2019-04-01 20:51:29                    0.0                 0.0   \n",
       "2  2019-04-01 18:00:49                    0.0                 0.0   \n",
       "\n",
       "   android_max_1days  smarttv_max_1days  iphone_max_1days  ...  \\\n",
       "0                0.0                0.0               0.0  ...   \n",
       "1                0.0                0.0               0.0  ...   \n",
       "2                0.0                0.0               0.0  ...   \n",
       "\n",
       "   apple_max_30days  pc_max_30days  activity_1to3  activity_1to7  \\\n",
       "0               0.0            0.0            0.0            0.0   \n",
       "1               0.0            4.0            0.0            0.0   \n",
       "2               0.0            6.0            0.0            0.0   \n",
       "\n",
       "   activity_1to14  activity_7to14  activity_7to21  activity_7to30  \\\n",
       "0             0.0        0.000000        0.000000        0.000000   \n",
       "1             0.0        0.005807        0.005774        0.003030   \n",
       "2             0.0        0.937031        0.832238        0.598121   \n",
       "\n",
       "   activity_14to30  label  \n",
       "0         0.000000    0.0  \n",
       "1         0.521792    1.0  \n",
       "2         0.638308    0.0  \n",
       "\n",
       "[3 rows x 146 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что датафрейм уже готов. 145 колонок с признаками и 1 label. Можно попробовать обучить модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим, менятеся ли label с течением времени\n",
    "temp_df = train.groupby('email').agg({'label':'mean'})\n",
    "temp_df[(temp_df.label != 0) & (temp_df.label != 1)].shape[0] / train.email.nunique() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего у 0.19% email видно изменение label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим, есть ли пересечения email на train и на test\n",
    "inner = train.merge(test, on='email')\n",
    "inner.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пересечений нет. Уберем email и даты из данных.\n",
    "X = train.drop(['cut_date', 'first_date', 'last_date','email','label'], axis=1)\n",
    "y = train['label']\n",
    "\n",
    "X_test = test.drop(['cut_date', 'first_date', 'last_date','email'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#возьмем модели из \"коробки\"\n",
    "models = [LogisticRegression(solver='liblinear'),\n",
    "          Lasso(), \n",
    "          Ridge(),\n",
    "          CatBoostClassifier(n_estimators=200, silent=True), #verbose=1000\n",
    "          RandomForestClassifier(n_estimators=100,n_jobs=-1),\n",
    "          #XGBClassifier(n_estimators=200),\n",
    "          LGBMClassifier(n_estimators=200), \n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 3-fold CV is : 0.6441 +/- 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                      | 1/6 [00:41<03:27, 41.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso 3-fold CV is : 0.6144 +/- 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 2/6 [00:48<02:05, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge 3-fold CV is : 0.6613 +/- 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 3/6 [00:50<01:06, 22.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x000001BFD4585188 3-fold CV is : 0.809 +/- 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [01:25<00:52, 26.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 3-fold CV is : 0.9709 +/- 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:34<00:38, 38.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier 3-fold CV is : 0.832 +/- 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:51<00:00, 28.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max results dict_keys(['RandomForestClassifier']) = [0.9709, array([0.9733731 , 0.96884724, 0.97043379])]\n"
     ]
    }
   ],
   "source": [
    "#сравним их на CV=3\n",
    "results_0 = compare_models(models, X, y, CV=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хочется выбрать RandomForest, но есть ощущение, что модель переобучилась.  \n",
    "\n",
    "Так как пользователи перемещаны, и при изменением days_to_end значение label не меняется, то получается, что при кросс-валидации попадаются пользователи, которых модель уже видела. Поэтому такой высокий скор.  \n",
    "\n",
    "Нужно проверить это предположение, отсортировать пользователей по email и использовать 15% holdout для верности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted = train.sort_values(by='email').reset_index().drop('index', axis=1)\n",
    "X_train = train_sorted[:153007].drop(['cut_date', 'first_date', 'last_date','email','label'], axis=1)\n",
    "y_train = train_sorted[:153007]['label']\n",
    "X_holdout = train_sorted[153007:].drop(['cut_date', 'first_date', 'last_date','email','label'], axis=1)\n",
    "y_holdout = train_sorted[153007:]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 3-fold CV is : 0.6382 +/- 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                      | 1/6 [00:28<02:20, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso 3-fold CV is : 0.6146 +/- 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 2/6 [00:34<01:26, 21.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge 3-fold CV is : 0.6553 +/- 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 3/6 [00:35<00:46, 15.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x000001BFD4585188 3-fold CV is : 0.633 +/- 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [01:06<00:40, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 3-fold CV is : 0.626 +/- 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [01:48<00:26, 26.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier 3-fold CV is : 0.6465 +/- 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:01<00:00, 20.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max results dict_keys(['Ridge']) = [0.6553, array([0.66832776, 0.64630109, 0.6511627 ])]\n"
     ]
    }
   ],
   "source": [
    "results_1 = compare_models(models, X_train, y_train, CV=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже на правду, но скор низковат :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отберем признаки для моделей  \n",
    "см. feature_selection_lgbm и feature_selection_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'n_estimators': [100, 200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#минимальный тюнинг параметров для модели1\n",
    "clf1 = LGBMClassifier(n_estimators=100)\n",
    "param_grid1 = {'n_estimators':[100,200,500]}\n",
    "grid_cv1 = GridSearchCV(clf1, param_grid1, cv=3, scoring='roc_auc', n_jobs=-1, return_train_score=True)\n",
    "grid_cv1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фичи из feature_selection_linear\n",
    "linears_features = ['num_country_max_1days', 'time_spent_sum_3days', 'time_spent_max_3days',\n",
    "       'num_title_ep_max_3days', 'num_title_ru_sum_3days', 'top_4_sum_3days',\n",
    "       'top_8_sum_3days', 'time_spent_sum_7days', 'num_title_ep_max_7days',\n",
    "       'num_title_ru_sum_7days', 'num_title_ru_max_7days',\n",
    "       'num_city_max_7days', 'top_1_sum_7days', 'top_5_sum_7days',\n",
    "       'top_9_sum_7days', 'top_10_sum_7days', 'iphone_max_7days',\n",
    "       'ipad_max_7days', 'time_spent_max_14days', 'num_title_ep_max_14days',\n",
    "       'num_title_ru_sum_14days', 'num_title_ru_max_14days',\n",
    "       'num_country_max_14days', 'top_1_sum_14days', 'top_4_sum_14days',\n",
    "       'top_5_sum_14days', 'top_6_sum_14days', 'top_9_sum_14days',\n",
    "       'smarttv_max_14days', 'ipad_max_14days', 'time_spent_sum_21days',\n",
    "       'num_title_ru_sum_21days', 'num_title_ru_max_21days',\n",
    "       'num_city_max_21days', 'top_3_sum_21days', 'top_5_sum_21days',\n",
    "       'top_7_sum_21days', 'top_8_sum_21days', 'top_10_sum_21days',\n",
    "       'iphone_max_21days', 'apple_max_21days', 'num_title_ep_max_30days',\n",
    "       'top_1_sum_30days', 'top_2_sum_30days', 'top_4_sum_30days',\n",
    "       'top_6_sum_30days', 'top_8_sum_30days', 'android_max_30days',\n",
    "       'smarttv_max_30days', 'apple_max_30days', 'activity_1to3',\n",
    "       'activity_7to30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=17, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(solver='liblinear', random_state=17)\n",
    "clf2.fit(X[linears_features],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgbm = grid_cv1.best_estimator_.predict_proba(X_test)[:,1]\n",
    "predictions_linear = clf2.predict_proba(X_test[linears_features])[:,1]\n",
    "# просто усредним прогнозы, хотя можно подобрать коэфициент\n",
    "predictions = (predictions_lgbm + predictions_linear) / 2\n",
    "#делаем сабмит\n",
    "pd.Series(predictions,\n",
    "          index=test.email,\n",
    "          name='prediction').to_csv('submit_01.csv', index_label='email', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом решении не предусмотра генерация фичей.\n",
    "Чтобы разобраться, какие фичи уже были предусмотрены 'TRAIN_PREPARED.csv' а какие еще можно сгенерить, нужно больше времени ;)\n",
    "Надеюсь, это не отразить на оценке моего решения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
